#notes #math112 #math #calc

Today is $\vec u \times \vec v$ 
- (cross product)
	- Both algebraically and geometrically
- Right Hand Rule
- Determinants are going to pop up
	- Conditions for parallel / orthogonal vectors
- Mayhaps area of a parallelogram
- Uses
	- Torque is cute n quirky
	- So are magnetic forces


---

- Bar Stool math
	- If you have three non colinear points, you can determine a plane
- Let's take some friendly neighborhood vectors, $\vec u$ and $\vec v$ that are not equal to each other and are not parallel 
	- Alright, let's say that $\vec u = \hat i$ and that $\vec v = \hat j$ 
		- These two together create the $x-y$ plane
	- Ok smart guy, let's say we have $\hat j \& \hat k$ 
		- That forms the y-z plane
- Given some plane, find vectors orthogonal to the plane
	- Anything on the $y-z$ plane that's orthogonal would be $\pm\hat k$ 
- Given the plane from $\vec u, \vec v$, find $\vec w$ that is $\perp$ to $\vec u$ and $\perp$ to $\vec v$
	- $\vec w = \vec u \times \vec v$
		- $\vec u=<u_{1},u_{2},u_{3}>$
		- $\vec v = <v_{1},v_{2}, v_{3}>$
		- $\vec w = <u_{2}v_{3}-u_{3}v_{2},u_{3}v_{1}-u_{1}v_{3},u_{1}v_{2}-u_{2}v_{1}>$
		- 23 32 31 13 12 21
	- Hey obligatory question, are we commutative?
		- Ehh, we're close
			- $\vec u \times \vec v = -\vec v \times \vec u$
			- What we in the buisness call "anti-commutative"
	- Assorted other properties (left as exercises to the reader to prove)
		- $(a \vec u)\times(b \vec v)=(ab)(\vec u \times \vec v)$ Associative
		- $\vec u \times (\vec v + \vec w)= \vec u \times \vec v + \vec u \times \vec w$ Distributive
		- $\vec u \times \vec u$ spits out the zero vector
			- I mean, that one makes sense without a proof
- Show that $\vec u \perp \vec w$
	- $\vec a * \vec b = |\vec a| |\vec b| \cos(\theta)=0$
	- $\vec u \cdot \vec w= u_{1}(u_{2}v_{3}-u_{3}v_{2})+u_{2}(u_{3}v_{1}-u_{1}v_{3})+u_{3}(u_{1}v_{2}-u_{2}v_{1})$
		- Okie dokie expansion time
		- $= u_{1}u_{2}v_{3}-u_{1}u_{3}v_{2}+u_{2}u_{3}v_{1}-u_{1}u_{2}v_{3}+u_{1}u_{3}v_{2}-u_{2}u_{3}v_{1}$
			- wtf did I just write
		- $0=0$ skip skip hooray
- this does indeed imply that $\vec u \perp \vec w$


- Let $\vec u = <1,0,0>=\hat \imath$
- Let $\vec v=<0,1,0>=\hat \jmath$
- $\vec u \times \vec v = <0*0-0*1,0*0-1*0,1-0>$
	- $u_{2}v_{3}-u_{3}v_{2}$
	- $u_{3}v_{1}-u_{1}v_{3}$
	- $u_{1}v_{2}-u_{2}v_{1}$
- We end up with $<0,0,1>=\hat k$


### Right Hand Rule
- Curl your fingers from the first term to the second (ie, $\vec u\times\vec v$), and thumb will point in the direction of the cross product

### Determinants
- Let's use determinants to calculate $\vec u \times \vec v$
- Let's say we have an n by n set of numbers
- $$\begin{matrix}  
a & b\\  
c & d  
\end{matrix}$$
- Determinant is $ad-bc$ 
- $$\begin{matrix}  
a & b & c\\  
d & e & f \\ g & h & i  
	\end{matrix}$$
	- Determinant would be $$a |\begin{matrix}  
e & f  \\ h & i  
\end{matrix} | - b |\begin{matrix}  
d & f  \\ g & i  
\end{matrix}| + c |\begin{matrix}  
d & e  \\ g & h  
\end{matrix}| $$

Which is the same thing as $a(ei-fh)-b(di-fg)+c(dh-eg)$

$$\vec u \times \vec v = | \begin{matrix}  
\hat\imath & \hat\jmath & \hat k  \\ u_{1} & u_{2}&u_{3} \\ v_{1} & v_{2} & v_{3}  
\end{matrix}|$$$$\hat\imath | \begin{matrix}  
u_{2} & u_{3}  \\ v_{2} & v_{3}  
\end{matrix}|  - \hat\jmath | \begin{matrix}  
u_{1} & u_{3}  \\ v_{1} & v_{3}  
\end{matrix}| + \hat k | \begin{matrix}  
u_{1} & u_{2}  \\ v_{1} & v_{3}  
\end{matrix}|$$

Magnitude of a cross product is the $\sin\theta$ instead of the $\cos\theta$ that it was for dot products

The cross product of two colinear vectors is always going to be a big ol 
# 0

The dot product though is $\pm |\vec u| \vec v|$

If they're perpendicular though, 