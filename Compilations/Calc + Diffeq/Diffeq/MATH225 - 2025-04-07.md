#notes #math225 #math 
### Systems of Ordinary Differential Equations
$$
\frac{dx_{1}}{dt}=x_{1}+x_{2}
$$
$$
\frac{dx_{2}}{dt}=x_{1}-x_{2}
$$
- Dealing with "coupled" differential equations
### Matrices!
- A matrix is a collection of numbers arranged in rows and columns
- Typical is to use a capital letter, often boldfaced in text
	- Texts will often use (), he uses \[] so I'm using those for my mental sake of not worrying about brackets.

$$
A=\begin{bmatrix}
1 & 2 & 3 & 4 \\
6 & 2 & 1 & 8 \\
0 & 1 & 2 & 1
\end{bmatrix}
$$
- This matrix that we're looking at has 3 rows and 4 columns, we say it's a $3 \times 4$ matrix
- We can index elements in the matrix as $A_{i,j}$
	- $A_{1,2}=2$
	- We're quite tragically not zero indexed. hate it here.
- There are a few important matrix operations we need to know how to do 
	- Why am I in this class and not in linalg. i like matrices a lot.
	- For addition, you add the corresponding elements
$$
A=\begin{bmatrix}
1 & 1 \\
3 & 2
\end{bmatrix}
, B = \begin{bmatrix}
0 & 3 \\
4 & 1
\end{bmatrix}, A+B = \begin{bmatrix}
1 & 4 \\
7 & 3
\end{bmatrix}
$$
- For scalar multiplication, you just multiply everything.
$$
c_{1} \begin{bmatrix}
1 & 2 \\
1 & 6
\end{bmatrix}
= \begin{bmatrix}
c_{1} & 2c_{1} \\
c_{1} & 6c_{1}
\end{bmatrix}
\text{ If c}_{1} \text{ is equal to 7, we'd have }\begin{bmatrix} 7 & 14 \\
7 & 42
\end{bmatrix}
$$
3. Transpose
	- Swap rows and columns, first row becomes first column, etc,etc
	- Denoted by $A^{T}$
$$
A= \begin{bmatrix}
0 & 1 \\
3 & 6 
\end{bmatrix} , A^{T}= \begin{bmatrix}
0 & 3 \\
1 & 6
\end{bmatrix}
$$
$$
A= \begin{bmatrix}
1 & 2 & 3 \\
4 & 5 & 6
\end{bmatrix}
, A^{T} = \begin{bmatrix}
1 & 4 \\
2 & 5 \\
3 & 6
\end{bmatrix}$$
	- If it wasn't already obvious, transpose can shit out a different size (ie, a $2 \times 3$ turns into a $3 \times 2$)
- Identity matrix has 1's on the primary diagonal, and 0's everywhere else (represented by $I$)
$$
I = \begin{bmatrix}
1 & 0 \\
0 & 1
\end{bmatrix}, I= \begin{bmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{bmatrix}
$$
- Vectors are, essentially, matrices
	- Just with either one row/column
	- $\bar{V} = <1,3>$ can be represented as either $\left[ \stackrel{1}{3} \right]$ or as $[1, 3]$ 
		- That doesn't quite look right with the stackrel but is the only way I could think to do it inline.
- Determinant of a matrix
	- Can be written as $\det(A)$ or as $|A|$ 
$$
A=\begin{bmatrix}
1 & 2 \\
3 & 4
\end{bmatrix}
, \det(A)=|A|=(1)(4)-(2)(3)=-2
$$
$$
A=\begin{bmatrix}
a & b \\
c & d
\end{bmatrix}
, \det(A) = ad-bc
$$
	- That's the determinant of a $2 \times 2$, which is nice and neat and tidy. $3\times 3$s and above are icky stinky, however, we're only really dealing with two equations and two unknowns, so we really *don't care*
- Multiplication!
$$
A=\begin{bmatrix}
1 & 2 & 3 \\
4 & 5 & 6
\end{bmatrix}
, B = \begin{bmatrix}
1 & 5 \\
6 & 2 \\
3 & 0
\end{bmatrix}
$$
- A is an $m\times n$ matrix, and $B$ is an $n\times p$ matrix
	- To multiply matrices, the number of columns in $A$ must equal the number of rows in $B$
$$
AB=\begin{bmatrix}
1+12+9 & 5+4+0 \\
4+30+18 & 20+10+0 
\end{bmatrix}
= \begin{bmatrix} 
22 & 9 \\
52 & 30
\end{bmatrix}
$$
$$
BA = \begin{bmatrix}
21 & 22 & 9 \\
14 & \dots & \dots \\
3 & \dots & \dots
\end{bmatrix}
$$
	- Matrix multiplication is NOT COMMUTATIVE! It **DOES MATTER** what order you put things in. 
- Eigenvalues and eigenvectors
$$
\begin{pmatrix}
1 & 2 \\
3 & 4
\end{pmatrix}
\begin{pmatrix}
3 \\
1
\end{pmatrix}=\begin{bmatrix}
5 \\
13
\end{bmatrix}
$$
- This is a matrix and a vector multiplied, where the vector is represented as a column vector.
- The matrix is a transformation that changes a vector into a new vector.
	- There is a special transformation that changes the length of the vector but not its direction.
		- This type of vector is called an eigenvector of the matrix and the scale factor of how much its length changes is called the eigenvalue of the matrix
			- $A\bar{v}=\lambda \bar{v}$, where $\lambda$ is some number that tells me how much the length of the vector changes
			- $\lambda$ is known as an eigenvalue 
			- To solve this equation, we need results from linear algebra, but we're just going to skip to the results